{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtW1V3IL6sZP",
        "outputId": "cc5cf0b6-29e9-4b23-d5eb-23799d32fdba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 96ms/step - accuracy: 0.2570 - loss: 4.0737 - val_accuracy: 0.4600 - val_loss: 2.4424 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.4892 - loss: 2.2309 - val_accuracy: 0.4700 - val_loss: 2.0848 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 74ms/step - accuracy: 0.5895 - loss: 1.6885 - val_accuracy: 0.5345 - val_loss: 1.9877 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 73ms/step - accuracy: 0.6456 - loss: 1.4250 - val_accuracy: 0.5421 - val_loss: 1.8500 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 73ms/step - accuracy: 0.6694 - loss: 1.3180 - val_accuracy: 0.6619 - val_loss: 1.3654 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 72ms/step - accuracy: 0.6893 - loss: 1.2649 - val_accuracy: 0.5804 - val_loss: 1.8177 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.7049 - loss: 1.2176 - val_accuracy: 0.6935 - val_loss: 1.2650 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 73ms/step - accuracy: 0.7236 - loss: 1.1850 - val_accuracy: 0.7433 - val_loss: 1.1111 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 71ms/step - accuracy: 0.7328 - loss: 1.1583 - val_accuracy: 0.6841 - val_loss: 1.4116 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.7519 - loss: 1.1148 - val_accuracy: 0.7276 - val_loss: 1.2123 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.7608 - loss: 1.1011 - val_accuracy: 0.6663 - val_loss: 1.4761 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 71ms/step - accuracy: 0.7628 - loss: 1.0947 - val_accuracy: 0.6822 - val_loss: 1.4123 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.7730 - loss: 1.0678 - val_accuracy: 0.6934 - val_loss: 1.3743 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.8119 - loss: 0.9440 - val_accuracy: 0.8329 - val_loss: 0.8247 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.8253 - loss: 0.8688 - val_accuracy: 0.8264 - val_loss: 0.8333 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.8320 - loss: 0.8235 - val_accuracy: 0.7911 - val_loss: 0.9632 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.8345 - loss: 0.8020 - val_accuracy: 0.8338 - val_loss: 0.7901 - learning_rate: 2.5000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.8410 - loss: 0.7787 - val_accuracy: 0.7795 - val_loss: 1.0018 - learning_rate: 2.5000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 69ms/step - accuracy: 0.8435 - loss: 0.7710 - val_accuracy: 0.8256 - val_loss: 0.8447 - learning_rate: 2.5000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 69ms/step - accuracy: 0.8483 - loss: 0.7533 - val_accuracy: 0.8264 - val_loss: 0.8090 - learning_rate: 2.5000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 73ms/step - accuracy: 0.8512 - loss: 0.7405 - val_accuracy: 0.8321 - val_loss: 0.7968 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 71ms/step - accuracy: 0.8549 - loss: 0.7299 - val_accuracy: 0.7817 - val_loss: 1.0385 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.8721 - loss: 0.6728 - val_accuracy: 0.8511 - val_loss: 0.7430 - learning_rate: 1.2500e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 72ms/step - accuracy: 0.8834 - loss: 0.6250 - val_accuracy: 0.8667 - val_loss: 0.6786 - learning_rate: 1.2500e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.8842 - loss: 0.6104 - val_accuracy: 0.8758 - val_loss: 0.6354 - learning_rate: 1.2500e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.8891 - loss: 0.5852 - val_accuracy: 0.8659 - val_loss: 0.6537 - learning_rate: 1.2500e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 73ms/step - accuracy: 0.8932 - loss: 0.5715 - val_accuracy: 0.8497 - val_loss: 0.7226 - learning_rate: 1.2500e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.8976 - loss: 0.5528 - val_accuracy: 0.8429 - val_loss: 0.7459 - learning_rate: 1.2500e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.8984 - loss: 0.5446 - val_accuracy: 0.8856 - val_loss: 0.5807 - learning_rate: 1.2500e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.9005 - loss: 0.5401 - val_accuracy: 0.8549 - val_loss: 0.6850 - learning_rate: 1.2500e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.9018 - loss: 0.5309 - val_accuracy: 0.8637 - val_loss: 0.6555 - learning_rate: 1.2500e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9029 - loss: 0.5235 - val_accuracy: 0.8963 - val_loss: 0.5451 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 73ms/step - accuracy: 0.9068 - loss: 0.5075 - val_accuracy: 0.8658 - val_loss: 0.6672 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9071 - loss: 0.5114 - val_accuracy: 0.8644 - val_loss: 0.6850 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9055 - loss: 0.5078 - val_accuracy: 0.8833 - val_loss: 0.5918 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 71ms/step - accuracy: 0.9082 - loss: 0.5002 - val_accuracy: 0.8989 - val_loss: 0.5357 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 71ms/step - accuracy: 0.9052 - loss: 0.5021 - val_accuracy: 0.8694 - val_loss: 0.6425 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 73ms/step - accuracy: 0.9101 - loss: 0.4985 - val_accuracy: 0.8801 - val_loss: 0.6005 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.9121 - loss: 0.4881 - val_accuracy: 0.8788 - val_loss: 0.5941 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9132 - loss: 0.4863 - val_accuracy: 0.8295 - val_loss: 0.8465 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9131 - loss: 0.4825 - val_accuracy: 0.8930 - val_loss: 0.5567 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.9253 - loss: 0.4470 - val_accuracy: 0.9018 - val_loss: 0.5309 - learning_rate: 6.2500e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9317 - loss: 0.4217 - val_accuracy: 0.9033 - val_loss: 0.5291 - learning_rate: 6.2500e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.9327 - loss: 0.4105 - val_accuracy: 0.9103 - val_loss: 0.4937 - learning_rate: 6.2500e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.9357 - loss: 0.4022 - val_accuracy: 0.8953 - val_loss: 0.5471 - learning_rate: 6.2500e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9375 - loss: 0.3941 - val_accuracy: 0.9077 - val_loss: 0.5048 - learning_rate: 6.2500e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9390 - loss: 0.3830 - val_accuracy: 0.9022 - val_loss: 0.5189 - learning_rate: 6.2500e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9403 - loss: 0.3789 - val_accuracy: 0.9110 - val_loss: 0.4875 - learning_rate: 6.2500e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 69ms/step - accuracy: 0.9409 - loss: 0.3770 - val_accuracy: 0.8993 - val_loss: 0.5252 - learning_rate: 6.2500e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 72ms/step - accuracy: 0.9407 - loss: 0.3710 - val_accuracy: 0.9141 - val_loss: 0.4773 - learning_rate: 6.2500e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9434 - loss: 0.3647 - val_accuracy: 0.8978 - val_loss: 0.5387 - learning_rate: 6.2500e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 71ms/step - accuracy: 0.9433 - loss: 0.3591 - val_accuracy: 0.9002 - val_loss: 0.5259 - learning_rate: 6.2500e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9447 - loss: 0.3566 - val_accuracy: 0.9021 - val_loss: 0.5208 - learning_rate: 6.2500e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.9449 - loss: 0.3530 - val_accuracy: 0.8958 - val_loss: 0.5605 - learning_rate: 6.2500e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9465 - loss: 0.3473 - val_accuracy: 0.9049 - val_loss: 0.4932 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 73ms/step - accuracy: 0.9486 - loss: 0.3341 - val_accuracy: 0.9125 - val_loss: 0.4799 - learning_rate: 3.1250e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9570 - loss: 0.3099 - val_accuracy: 0.9118 - val_loss: 0.4852 - learning_rate: 3.1250e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9582 - loss: 0.3087 - val_accuracy: 0.9088 - val_loss: 0.5007 - learning_rate: 3.1250e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 73ms/step - accuracy: 0.9572 - loss: 0.3064 - val_accuracy: 0.9172 - val_loss: 0.4634 - learning_rate: 3.1250e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9596 - loss: 0.2981 - val_accuracy: 0.9213 - val_loss: 0.4390 - learning_rate: 3.1250e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9588 - loss: 0.3017 - val_accuracy: 0.9118 - val_loss: 0.4866 - learning_rate: 3.1250e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.9620 - loss: 0.2889 - val_accuracy: 0.9215 - val_loss: 0.4415 - learning_rate: 3.1250e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9627 - loss: 0.2864 - val_accuracy: 0.9151 - val_loss: 0.4873 - learning_rate: 3.1250e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 73ms/step - accuracy: 0.9626 - loss: 0.2870 - val_accuracy: 0.9160 - val_loss: 0.4619 - learning_rate: 3.1250e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.9614 - loss: 0.2882 - val_accuracy: 0.9157 - val_loss: 0.4583 - learning_rate: 3.1250e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 73ms/step - accuracy: 0.9680 - loss: 0.2675 - val_accuracy: 0.9198 - val_loss: 0.4569 - learning_rate: 1.5625e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 72ms/step - accuracy: 0.9687 - loss: 0.2658 - val_accuracy: 0.9209 - val_loss: 0.4517 - learning_rate: 1.5625e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9694 - loss: 0.2616 - val_accuracy: 0.9182 - val_loss: 0.4648 - learning_rate: 1.5625e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 72ms/step - accuracy: 0.9664 - loss: 0.2655 - val_accuracy: 0.9183 - val_loss: 0.4633 - learning_rate: 1.5625e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.9715 - loss: 0.2537 - val_accuracy: 0.9213 - val_loss: 0.4477 - learning_rate: 1.5625e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 72ms/step - accuracy: 0.9722 - loss: 0.2486 - val_accuracy: 0.9230 - val_loss: 0.4421 - learning_rate: 7.8125e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9728 - loss: 0.2457 - val_accuracy: 0.9250 - val_loss: 0.4342 - learning_rate: 7.8125e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9727 - loss: 0.2448 - val_accuracy: 0.9263 - val_loss: 0.4386 - learning_rate: 7.8125e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 73ms/step - accuracy: 0.9729 - loss: 0.2437 - val_accuracy: 0.9276 - val_loss: 0.4320 - learning_rate: 7.8125e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 73ms/step - accuracy: 0.9753 - loss: 0.2389 - val_accuracy: 0.9261 - val_loss: 0.4370 - learning_rate: 7.8125e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 69ms/step - accuracy: 0.9746 - loss: 0.2409 - val_accuracy: 0.9225 - val_loss: 0.4501 - learning_rate: 7.8125e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 69ms/step - accuracy: 0.9754 - loss: 0.2365 - val_accuracy: 0.9258 - val_loss: 0.4379 - learning_rate: 7.8125e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 70ms/step - accuracy: 0.9743 - loss: 0.2379 - val_accuracy: 0.9264 - val_loss: 0.4276 - learning_rate: 7.8125e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9755 - loss: 0.2360 - val_accuracy: 0.9202 - val_loss: 0.4593 - learning_rate: 7.8125e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9746 - loss: 0.2365 - val_accuracy: 0.9221 - val_loss: 0.4552 - learning_rate: 7.8125e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9773 - loss: 0.2277 - val_accuracy: 0.9238 - val_loss: 0.4535 - learning_rate: 7.8125e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 71ms/step - accuracy: 0.9754 - loss: 0.2349 - val_accuracy: 0.9295 - val_loss: 0.4255 - learning_rate: 7.8125e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9765 - loss: 0.2313 - val_accuracy: 0.9270 - val_loss: 0.4305 - learning_rate: 7.8125e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 73ms/step - accuracy: 0.9775 - loss: 0.2275 - val_accuracy: 0.9242 - val_loss: 0.4432 - learning_rate: 7.8125e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 72ms/step - accuracy: 0.9775 - loss: 0.2294 - val_accuracy: 0.9246 - val_loss: 0.4431 - learning_rate: 7.8125e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9758 - loss: 0.2300 - val_accuracy: 0.9240 - val_loss: 0.4394 - learning_rate: 7.8125e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 72ms/step - accuracy: 0.9781 - loss: 0.2244 - val_accuracy: 0.9223 - val_loss: 0.4484 - learning_rate: 7.8125e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.9775 - loss: 0.2258 - val_accuracy: 0.9260 - val_loss: 0.4372 - learning_rate: 3.9063e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9787 - loss: 0.2214 - val_accuracy: 0.9266 - val_loss: 0.4396 - learning_rate: 3.9063e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9779 - loss: 0.2252 - val_accuracy: 0.9256 - val_loss: 0.4394 - learning_rate: 3.9063e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.9776 - loss: 0.2233 - val_accuracy: 0.9248 - val_loss: 0.4389 - learning_rate: 3.9063e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9781 - loss: 0.2221 - val_accuracy: 0.9266 - val_loss: 0.4377 - learning_rate: 3.9063e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 73ms/step - accuracy: 0.9789 - loss: 0.2184 - val_accuracy: 0.9254 - val_loss: 0.4391 - learning_rate: 1.9531e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 73ms/step - accuracy: 0.9788 - loss: 0.2201 - val_accuracy: 0.9276 - val_loss: 0.4319 - learning_rate: 1.9531e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9795 - loss: 0.2178 - val_accuracy: 0.9264 - val_loss: 0.4363 - learning_rate: 1.9531e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.9789 - loss: 0.2176 - val_accuracy: 0.9264 - val_loss: 0.4380 - learning_rate: 1.9531e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.9807 - loss: 0.2159 - val_accuracy: 0.9269 - val_loss: 0.4375 - learning_rate: 1.9531e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 73ms/step - accuracy: 0.9807 - loss: 0.2157 - val_accuracy: 0.9269 - val_loss: 0.4382 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.9811 - loss: 0.2144 - val_accuracy: 0.9260 - val_loss: 0.4386 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 72ms/step - accuracy: 0.9793 - loss: 0.2144 - val_accuracy: 0.9275 - val_loss: 0.4363 - learning_rate: 1.0000e-06\n",
            "313/313 - 3s - 10ms/step - accuracy: 0.9295 - loss: 0.4255\n",
            "\n",
            "Test accuracy: 0.93\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Loading CIFAR-10 Dataset\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalizing the images\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# One-hot encoding the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Model Definition with Increased Complexity\n",
        "input_layer = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "# First Block with More Filters and Extra Convolution Layer\n",
        "X = layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005))(input_layer)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation(\"relu\")(X)\n",
        "X = layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation(\"relu\")(X)\n",
        "X = layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005))(X)  # Extra Layer\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation(\"relu\")(X)\n",
        "X = layers.MaxPooling2D((2, 2))(X)\n",
        "X = layers.Dropout(0.3)(X)\n",
        "\n",
        "# Second Block with Increased Filters and Extra Convolution Layer\n",
        "X = layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation(\"relu\")(X)\n",
        "X = layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation(\"relu\")(X)\n",
        "X = layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005))(X)  # Extra Layer\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation(\"relu\")(X)\n",
        "X = layers.MaxPooling2D((2, 2))(X)\n",
        "X = layers.Dropout(0.3)(X)\n",
        "\n",
        "# Third Block with Increased Filters\n",
        "X = layers.Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.0005))(X)\n",
        "X = layers.BatchNormalization()(X)\n",
        "X = layers.Activation(\"relu\")(X)\n",
        "X = layers.MaxPooling2D((2, 2))(X)\n",
        "X = layers.Dropout(0.4)(X)\n",
        "\n",
        "# Output Block with Increased Dense Units\n",
        "X = layers.Flatten()(X)\n",
        "X = layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.0005))(X)\n",
        "X = layers.Dropout(0.4)(X)\n",
        "output_layer = layers.Dense(10, activation=\"softmax\", kernel_regularizer=regularizers.l2(0.0005))(X)\n",
        "\n",
        "# Create the Model\n",
        "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the Model with a Lower Learning Rate\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set up callbacks with Increased Patience for Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Train the Model with Data Augmentation\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=64),\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=100,\n",
        "    callbacks=[early_stopping, lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc:.2f}')\n"
      ]
    }
  ]
}